{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libares"
      ],
      "metadata": {
        "id": "ym1_gmsAjDOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLms5b4ljAhe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define our dataset"
      ],
      "metadata": {
        "id": "QMmGnPSOjywK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About Dataset\n",
        "### This dataset has been developed from the cry audio files available in the Github repository donateacry-corpus\n",
        "### All temporal, prosodic, image and cepstral domain features for each cry audio including mean and individual MFCCs are present. Use this dataset to analyse cry patterns of various cry reason classes and train a model to predict cry reasons for unseen data\n",
        "## Classes for prediction\n",
        "### 0 - belly pain\n",
        "### 1 - burping\n",
        "### 2 - discomfort\n",
        "### 3 - hungry\n",
        "### 4 - tired\n",
        "457 rows, 27 columns"
      ],
      "metadata": {
        "id": "BsppgEIskKVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train and X_test should contain your input audio data (e.g., spectrograms or MFCCs).\n",
        "# y_train and y_test should contain corresponding labels (e.g., 0 for non-baby speech and 1 for baby speech).\n",
        "# Example data loading:\n",
        "# X_train = np.load('X_train.npy')\n",
        "# X_test = np.load('X_test.npy')\n",
        "# y_train = np.load('y_train.npy')\n",
        "# y_test = np.load('y_test.npy')"
      ],
      "metadata": {
        "id": "ukj62fcsjb3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Define the 1D CNN model\n"
      ],
      "metadata": {
        "id": "ptOCatrajbxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n"
      ],
      "metadata": {
        "id": "WODg86f8jbuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile the model"
      ],
      "metadata": {
        "id": "EyzWsQ39jbq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YktwQYSPjbnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the model summary"
      ],
      "metadata": {
        "id": "4Vh4BP90jf2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "e2TILZvmjbgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "d9CoWukzjXuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "dz7nmR2WjUNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model on test data"
      ],
      "metadata": {
        "id": "HKPErVQejRNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "AyUgupcRjQSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make predictions"
      ],
      "metadata": {
        "id": "YtMJS1XLjMQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "# You can use the predictions for further analysis or visualization"
      ],
      "metadata": {
        "id": "kuD6_B-0jJH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}